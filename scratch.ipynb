{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "from skimage import filters\n",
    "from scipy import ndimage\n",
    "from skimage.measure import block_reduce\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_calc_2D(in_shp, trgt_shp):\n",
    "    return int(in_shp[0]/trgt_shp[0]), int(in_shp[1]/trgt_shp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_fun(arr, title, size=(10,10)):\n",
    "    plt.figure(figsize=size)\n",
    "    plt.imshow(arr)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'.\\data\\Well2_100min_XY1_EGFP_10X.tif'\n",
    "img = Image.open(path)\n",
    "img_arr = np.array(img)\n",
    "\n",
    "path = r'.\\data\\Well2_100min_XY1_DAPI_10X.tif'\n",
    "img = Image.open(path)\n",
    "dapi_arr = np.array(img)\n",
    "\n",
    "path = r'.\\data\\Well2_100min_XY1_CY5_10X1.tif'\n",
    "img = Image.open(path)\n",
    "cy5_arr = np.array(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtraction refers to middle section to be subtracted out of calculations from dapi stain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_size = dapi_arr.shape\n",
    "subtraction = cv2.resize(dapi_arr, dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\n",
    "subtraction = ndimage.gaussian_filter(subtraction, 10)\n",
    "subtraction = subtraction/np.max(subtraction)*100\n",
    "subtraction[subtraction < 50] = 0\n",
    "subtraction[subtraction >= 50] = 1\n",
    "subtraction = ndimage.binary_dilation(subtraction.astype(np.uint8), iterations=10)\n",
    "subtraction = 1 - subtraction\n",
    "subtraction = cv2.resize(subtraction.astype(np.float), dsize=orig_size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "plt_fun(subtraction, \"subtraction\", size=(5,5))\n",
    "plt_fun(dapi_arr, \"original\", size=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blur_detector\n",
    "import cv2\n",
    "nonblur_arr = np.multiply(img_arr, subtraction)[2000:3000, 2000:3000]\n",
    "\n",
    "#return cv2.Laplacian(arr, cv2.CV_64F).var()\n",
    "new_arr = []\n",
    "\n",
    "blck_sz = 100\n",
    "for ind_1, i in enumerate(range(int((img_arr.shape[0] % blck_sz)/2), img_arr.shape[0], blck_sz)):\n",
    "    new_arr.append([])\n",
    "    for j in range(int((img_arr.shape[1] % blck_sz)/2), img_arr.shape[1], blck_sz):\n",
    "        curr_arr = img_arr[i:i+blck_sz, j:j+blck_sz]\n",
    "        new_arr[ind_1].append(cv2.Laplacian(curr_arr, cv2.CV_64F).var())\n",
    "    print(f\"Processing {i/img_arr.shape[0]:.2%}\", end='\\r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(np.array(new_arr))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below section adaptively subtracts out background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_arr = np.multiply(img_arr, subtraction)\n",
    "new_arr = np.zeros_like(img_arr)\n",
    "\n",
    "sample_area = 100\n",
    "s_len = int(sample_area/2)\n",
    "for i in range(s_len,img_arr.shape[0], sample_area):\n",
    "    for j in range(s_len,img_arr.shape[1], sample_area):\n",
    "        curr_area = img_arr[i-s_len:i+s_len, j-s_len:j+s_len]\n",
    "        background = np.percentile(curr_area, 0.5)\n",
    "        curr_area = curr_area - background\n",
    "        curr_area[curr_area < 0] = 0\n",
    "        new_arr[i-s_len:i+s_len, j-s_len:j+s_len] = curr_area\n",
    "    print(f\"Processing {i/img_arr.shape[0]:.2%}\", end='\\r')\n",
    "\n",
    "# don't want to normalize because wanna see time variance?\n",
    "#egfp_arr = np.multiply(new_arr, subtraction)/np.max(new_arr)*255\n",
    "egfp_arr = np.multiply(new_arr, subtraction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_fun((egfp_arr/np.max(egfp_arr)*255), \"egfp_arr\", size=(5,5))\n",
    "plt_fun(img_arr, \"base_img\", size=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove low-brightness noise and invert object brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_labels[filtered_labels > 0] = 255\n",
    "cv2.imwrite(\"egfp_arr.png\", egfp_arr, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize255(img):\n",
    "    return img/np.max(img)*255\n",
    "\n",
    "def normalize1(img):\n",
    "    return (img/np.max(img)).astype(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Using Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_arr = normalize255(np.array(egfp_arr[3000:3500, 3000:3500]))\n",
    "filtered_arr[filtered_arr < 3] = 0\n",
    "filtered_arr = normalize1(filtered_arr)\n",
    "entr_img = normalize1(entropy(filtered_arr, disk(3)))\n",
    "\n",
    "filtered_arr = cv2.merge([filtered_arr, filtered_arr, filtered_arr])\n",
    "entr_img = cv2.merge([np.zeros_like(entr_img), entr_img, np.zeros_like(entr_img)])\n",
    "\n",
    "added_image = cv2.addWeighted(filtered_arr,1,entr_img,0.3,0)\n",
    "\n",
    "%matplotlib auto\n",
    "#plt_fun(added_image, \"added\", size=(10,10))\n",
    "plt_fun(filtered_arr, \"orig\", size=(10,10))\n",
    "plt_fun(entr_img, \"entropy\", size=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Using simple thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_arr = normalize255(np.array(egfp_arr))\n",
    "filtered_arr[filtered_arr < 6] = 0\n",
    "filtered_arr[filtered_arr > 30] = 0\n",
    "\n",
    "%matplotlib auto\n",
    "\n",
    "plt_fun(np.array(egfp_arr[3000:3500, 3000:3500]), \"orig\", size=(10,10))\n",
    "plt_fun(filtered_arr[3000:3500, 3000:3500], \"filtered\", size=(10,10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_arr = filtered_arr\n",
    "sum_arr[sum_arr > 0] = 1\n",
    "area_calc = block_reduce(sum_arr, (100,100), np.sum)\n",
    "\n",
    "plt_fun(area_calc, \"summed\", size=(10,10))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f28b055f488624bbcb43e5427a1e1a08ddfd594a0a14b1c81dd9f4cacf7b99e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('MacVis2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
